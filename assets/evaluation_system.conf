[evaluation_system]
# Freva - Free Evaluation System Framework configuration file
# This file contains the necessary configuration information
# which is needed to run freva
#
# Username(s) - comma separated - of the admins of the proejct
admins=
#
# An Infromative project name
project_name=freva
# The url the freva web ui can be accessed with
project_website=

# Main configuration path of the freva instance default to the etc dir
# of the python environment
root_dir=
#
# The location of the work direcotry for is user specific data
base_dir_location=${root_dir}/freva_output
#

#: Type of directory structure that will be used to maintain state:
#:
#:    local   := <home>/<base_dir>...
#:    central := <base_dir_location>/<username>/<base_dir>...
#:
directory_structure_type=scratch

# The directory name of the <base_dir> (only used if `directory_structure_type`
# is set to central - defaults to `project_name`
base_dir=${project_name}

# TODO: this should be deleted
scratch_dir=${base_dir_location}/$$USER

# Workload manager configuration
# Workload manager system - currently the following workload manger systems are
# available: local (no workload manager), lsf, moab, oar, pbs, sge, slurm
scheduler_system=local
# The directory where temporary job scripts are created
scheduler_input_dir=/tmp/${scheduler_system}_output
# The output directory where stdour/stderr of the jobs are stored
scheduler_output_dir=${base_dir_location}/share/${scheduler_system}_output

# The directory data where preview data (images etc) for the web ui
# is stored.
preview_path=${base_dir_location}/share/preview
# The number of processes used to convert images created by plugins
# for display in the web ui.
number_of_processes=6

#: Path to the directory where users can add an share project specific data
project_data=${base_dir_location}/data/crawl_my_data


#: database path

#: mySQL settings
db.host=
db.user=
db.passwd=
db.db=
db.port=3306

#group for external users
#external_group=frevaext

#: Define access to the solr instance
solr.host=
solr.port=8989
solr.core=files

#shellinabox
#shellmachine=None
#shellport=4200

# Workload manager job configuration
# NOTE: The options are workload manager agnostic - except of the
# extra_options flag: which must be in accordance to the utilized
# workload manager.
[scheduler_options]
#partition=
#memory=256GiB
#queue=gpu
#project=ch1187
#walltime=08:00:00
#cpus=12
##Additional options (specific to the workload manager)
#extra_options=--qos=test, --array=20

#[scheduler_options_extern]
#partition=
#memory=256GiB
#queue=gpu
#project=ch1187
#walltime=08:00:00
#cpus=12
##Additional options (specific to the workload manager)
#extra_options=--qos=test, --array=20

#[plugin:animator]
#python_path=${evaluation_system:root_dir}/plugins/animator
#module=animator
